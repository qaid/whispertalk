# Look Ma No Hands

Fast, local voice dictation for macOS. Press Caps Lock, speak, and get perfectly formatted textâ€”instantly.

## âœ¨ Features

- **Lightning Fast**: ~1 second transcription with Core ML acceleration (8-15x faster than competitors)
- **System-wide**: Works in any app, any text field
- **Caps Lock trigger**: Simple toggleâ€”press once to start, again to stop
- **100% Local**: Everything runs on your Mac, no cloud, no internet required
- **Smart formatting**: Automatic capitalization, punctuation, and cleanup
- **Privacy first**: Your voice never leaves your computer
- **Native macOS**: Beautiful floating indicator, menu bar integration

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
# Clone the repository
git clone https://github.com/qaid/lookmanohands.git
cd lookmanohands

# Build
swift build -c release
```

### 2. Download Whisper Model

**Recommended**: Use the tiny model with Core ML for best speed:

```bash
cd ~/.whisper/models

# Download tiny model (75 MB)
curl -L -O https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.bin

# Download Core ML acceleration (14 MB) - 5-10x faster!
curl -L -O https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny-encoder.mlmodelc.zip
unzip ggml-tiny-encoder.mlmodelc.zip
rm ggml-tiny-encoder.mlmodelc.zip
```

Alternatively, Look Ma No Hands can download models for you on first launch.

### 3. Run

```bash
.build/release/LookMaNoHands
```

### 4. Grant Permissions

On first launch, grant:
1. **Microphone access**: To capture your voice
2. **Accessibility access**: To insert text anywhere

## ğŸ¯ Usage

1. Click any text field in any app
2. Press **Caps Lock** to start recording
3. Speak naturally
4. Press **Caps Lock** again to stop
5. Formatted text appears instantly!

## âš¡ Performance

| Model | Size | Speed (16s audio) | Accuracy | Recommended |
|-------|------|-------------------|----------|-------------|
| **tiny** | 75 MB | **~1s** (Core ML) | Good for dictation | âœ… **Yes** |
| base | 142 MB | ~2-3s (Core ML) | Better accuracy | For longer transcriptions |
| small | 466 MB | ~5-7s (Core ML) | High accuracy | Complex terminology |

**With Core ML**: 8-15x faster on Apple Silicon!
**Without Core ML**: Falls back to CPU (still works, just slower)

See [PERFORMANCE.md](PERFORMANCE.md) for optimization details.

## ğŸ› ï¸ Requirements

- **macOS 14+** (Sonoma or later)
- **Apple Silicon** recommended (Intel Macs supported but slower)
- **~200 MB disk space** for tiny model + Core ML

## ğŸ“ How It Works

1. **Audio Capture**: AVFoundation records high-quality 16kHz mono audio
2. **Transcription**: Whisper.cpp with Core ML converts speech to text
3. **Formatting**: Rule-based system adds capitalization and punctuation
4. **Insertion**: Accessibility API pastes text directly into focused field

All processing happens on your Mac in under 1 second!

## ğŸ”§ Configuration

Click the menu bar icon to:
- Download different Whisper models
- View permissions status
- Quit the app

## ğŸ› Troubleshooting

**Core ML not loading?**
- Check console for `whisper_init_state: Core ML model loaded`
- Ensure `.mlmodelc` file is in `~/.whisper/models/`
- Requires macOS 12+ and Apple Silicon for best performance

**Text not inserting?**
- Some apps restrict accessibilityâ€”Look Ma No Hands falls back to clipboard
- Check Accessibility permissions in System Settings

**Caps Lock not working?**
- The app monitors Caps Lock presses (doesn't change actual Caps Lock state)
- Ensure Accessibility permission is granted

## ğŸ“š Project Structure

```
LookMaNoHands/
â”œâ”€â”€ Sources/LookMaNoHands/
â”‚   â”œâ”€â”€ App/              # Main app and menu bar
â”‚   â”œâ”€â”€ Services/         # Core functionality
â”‚   â”‚   â”œâ”€â”€ AudioRecorder.swift       # 16kHz audio capture + normalization
â”‚   â”‚   â”œâ”€â”€ WhisperService.swift      # Whisper.cpp integration + Core ML
â”‚   â”‚   â”œâ”€â”€ TextFormatter.swift       # Rule-based text cleanup
â”‚   â”‚   â”œâ”€â”€ TextInsertionService.swift # Accessibility API
â”‚   â”‚   â””â”€â”€ KeyboardMonitor.swift     # Caps Lock detection
â”‚   â”œâ”€â”€ Views/            # SwiftUI + AppKit UI
â”‚   â””â”€â”€ Models/           # State management
â”œâ”€â”€ docs/                 # Architecture documentation
â””â”€â”€ PERFORMANCE.md        # Optimization guide
```

## ğŸ”’ Privacy

Look Ma No Hands is 100% local:
- âœ… Audio never sent to cloud
- âœ… No telemetry or analytics
- âœ… No internet required (after model download)
- âœ… Open sourceâ€”verify for yourself

## ğŸš§ Known Limitations

- Caps Lock monitoring requires Accessibility permission
- Some sandboxed apps may not allow direct text insertion
- Best accuracy with clear audio in quiet environments
- English-only (Whisper supports other languages, but not tested)

## ğŸ“– Advanced Usage

### Using Different Models

Download other models from [Hugging Face](https://huggingface.co/ggerganov/whisper.cpp/tree/main):

```bash
cd ~/.whisper/models
curl -L -O https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin
curl -L -O https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base-encoder.mlmodelc.zip
unzip ggml-base-encoder.mlmodelc.zip
```

WhisperTalk automatically uses the best model it finds (prefers tiny â†’ base â†’ small).

### Building for Release

```bash
swift build -c release
cp .build/release/WhisperTalk ~/Applications/
```

## ğŸ¤ Contributing

Contributions welcome! Please read [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) first.

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file.

## ğŸ™ Acknowledgments

- [whisper.cpp](https://github.com/ggerganov/whisper.cpp) - Fast Whisper inference
- [SwiftWhisper](https://github.com/exPHAT/SwiftWhisper) - Swift bindings
- Inspired by macOS built-in dictation, but faster and fully local

---

**Made with â¤ï¸ for productive macOS users who value privacy and speed.**
